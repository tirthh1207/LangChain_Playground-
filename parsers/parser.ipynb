{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "ce0e3848",
            "metadata": {},
            "source": [
                "# Output Parsers in LangChain\n",
                "\n",
                "## What are Output Parsers?\n",
                "\n",
                "**Output Parsers** are components that transform raw LLM outputs into structured, usable formats. LLMs inherently return plain text strings, but applications often need structured data (JSON, objects, lists, etc.). Output parsers bridge this gap.\n",
                "\n",
                "### Why Use Output Parsers?\n",
                "\n",
                "1. **Structure from Text**: Convert unstructured LLM output into structured data\n",
                "2. **Type Safety**: Ensure data matches expected types and schemas\n",
                "3. **Validation**: Enforce constraints and rules on generated data\n",
                "4. **Integration**: Make output compatible with downstream systems\n",
                "5. **Error Prevention**: Catch formatting issues before they cause problems\n",
                "6. **Composability**: Chain with prompts and models seamlessly\n",
                "\n",
                "### The Two-Part Job of Output Parsers\n",
                "\n",
                "1. **Format Instructions**: Inject instructions into prompts telling LLMs how to format responses\n",
                "   - Example: \"Return a valid JSON object with keys: name, age, email\"\n",
                "2. **Parsing**: Transform the final text response into a Python object\n",
                "   - Example: Convert JSON string → Python dictionary\n",
                "\n",
                "### Output Parser Workflow\n",
                "\n",
                "```\n",
                "LLM Output (text string)\n",
                "        ↓\n",
                "[Validation] → Valid? → Parsed Output (Python object)\n",
                "        ↓ Invalid\n",
                "    [Retry/Error]\n",
                "```\n",
                "\n",
                "### Key Principle\n",
                "\n",
                "**Better structured output = More reliable applications**. Output parsers ensure consistent, predictable data formats for downstream processing.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "45a2fead",
            "metadata": {},
            "source": [
                "## StrOutputParser\n",
                "\n",
                "### Definition\n",
                "\n",
                "**StrOutputParser** is the simplest output parser in LangChain. It extracts just the **string content** from LLM message objects, stripping away metadata and converting them into plain Python strings.\n",
                "\n",
                "### Key Features\n",
                "\n",
                "- **Simplest Parser**: No schema or validation required\n",
                "- **Text Extraction**: Pulls content from AIMessage objects\n",
                "- **Passthrough Compatible**: Perfect for chaining with multiple prompts\n",
                "- **No Validation**: Accepts any text output as-is\n",
                "- **Lightweight**: Minimal overhead\n",
                "\n",
                "### How It Works\n",
                "\n",
                "```\n",
                "AIMessage(content=\"Hello, I am Claude\", metadata={...})\n",
                "            ↓ [StrOutputParser]\n",
                "         \"Hello, I am Claude\"\n",
                "```\n",
                "\n",
                "### Use Cases\n",
                "\n",
                "- Simple text generation and completion\n",
                "- Multi-step chains (output of one → input of next)\n",
                "- Summarization tasks\n",
                "- Content generation\n",
                "- When you just need the text, not structure\n",
                "\n",
                "### When to Use\n",
                "\n",
                "✅ **Use StrOutputParser when:**\n",
                "- Output is simple text/prose\n",
                "- Chaining multiple prompt-model steps\n",
                "- Data doesn't need strict structure\n",
                "- Speed is important (no validation)\n",
                "\n",
                "❌ **Don't use when:**\n",
                "- Output needs to be JSON or structured\n",
                "- Type safety is critical\n",
                "- Validation rules required\n",
                "- Complex data extraction needed\n",
                "\n",
                "### Advanced Example: Chain of Thought\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "78dd9e29",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "### Point-wise Summary of the Beginner's Guide to Large Language Models (LLMs)\n",
                        "\n",
                        "1. **Introduction**:\n",
                        "   - Large Language Models (LLMs) are AI models designed to process and generate human-like text.\n",
                        "   - They are trained on vast amounts of text data, enabling them to understand and generate text across multiple languages and contexts.\n",
                        "   - Applications include customer service, content creation, and language translation.\n",
                        "\n",
                        "2. **Definition of LLMs**:\n",
                        "   - LLMs predict the next word in a sequence of text based on patterns learned from large datasets.\n",
                        "   - The goal is to generate coherent and contextually relevant text.\n",
                        "\n",
                        "3. **Key Features of LLMs**:\n",
                        "   - **Massive Size**: Contain billions or trillions of parameters.\n",
                        "   - **Contextual Understanding**: Can understand the context of sentences and conversations.\n",
                        "   - **Multilingual Support**: Capable of processing and generating text in multiple languages.\n",
                        "   - **Fine-Tuning**: Can be adapted for specific tasks through fine-tuning.\n",
                        "\n",
                        "4. **How LLMs Work**:\n",
                        "   - **Training Process**:\n",
                        "     - **Data Collection**: Involves large datasets of text from various sources.\n",
                        "     - **Model Architecture**: Typically uses Transformer models.\n",
                        "     - **Training**: Uses backpropagation to adjust parameters and minimize differences between predicted and actual text.\n",
                        "     - **Evaluation**: Measures performance on a separate dataset.\n",
                        "   - **Inference Process**:\n",
                        "     - **Input**: Takes a sequence of text as input.\n",
                        "     - **Prediction**: Generates the next word based on learned patterns.\n"
                    ]
                }
            ],
            "source": [
                "from langchain_core.prompts import PromptTemplate\n",
                "from langchain_core.output_parsers import StrOutputParser\n",
                "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
                "from dotenv import load_dotenv\n",
                "load_dotenv()\n",
                "\n",
                "llm = HuggingFaceEndpoint(\n",
                "    repo_id=\"Qwen/Qwen2.5-7B-Instruct\",\n",
                "    task=\"text-generation\",\n",
                "    temperature=0.3)\n",
                "model = ChatHuggingFace(llm=llm)\n",
                "\n",
                "# 1. StrOutputParser example code-------\n",
                "\n",
                "from langchain_core.output_parsers import StrOutputParser\n",
                "\n",
                "# Prompt 1 → detailed report\n",
                "template1 = PromptTemplate(\n",
                "    template=\"\"\"\n",
                "You are a helpful AI tutor.\n",
                "Write a beginner friendly detailed report on {topic}.\n",
                "\"\"\",\n",
                "    input_variables=[\"topic\"]\n",
                ")\n",
                "\n",
                "# Prompt 2 → summary\n",
                "template2 = PromptTemplate(\n",
                "    template=\"\"\"\n",
                "Write a short point-wise summary of the following text:\n",
                "{text}\n",
                "\"\"\",\n",
                "    input_variables=[\"text\"]\n",
                ")\n",
                "\n",
                "parser = StrOutputParser()\n",
                "\n",
                "chain = template1 | model | parser | template2 | model | parser\n",
                "\n",
                "result = chain.invoke({\"topic\": \"LLM\"})\n",
                "print(result)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cf10b609",
            "metadata": {},
            "source": [
                "## JsonOutputParser\n",
                "\n",
                "### Definition\n",
                "\n",
                "**JsonOutputParser** ensures LLM output is formatted as **valid JSON** and automatically converts it into a Python dictionary for easy access.\n",
                "\n",
                "### Key Features\n",
                "\n",
                "- **Format Instructions**: Automatically injects JSON formatting rules\n",
                "- **Validation**: Ensures output is valid JSON before parsing\n",
                "- **Dictionary Conversion**: Returns Python `dict`, not string\n",
                "- **Flexible Structure**: No schema required - works with any JSON\n",
                "- **Partial Variables**: Supports injecting instructions into prompts\n",
                "\n",
                "### How It Works\n",
                "\n",
                "```\n",
                "LLM Output (JSON string):\n",
                "{\"name\": \"Alice\", \"age\": 30}\n",
                "        ↓ [JsonOutputParser]\n",
                "Python Dictionary:\n",
                "{\"name\": \"Alice\", \"age\": 30}\n",
                "```\n",
                "\n",
                "### Use Cases\n",
                "\n",
                "- API responses\n",
                "- Configuration generation\n",
                "- Multi-field data extraction\n",
                "- Key-value pair generation\n",
                "- Flexible structured data\n",
                "\n",
                "### Advantages Over StrOutputParser\n",
                "\n",
                "| Aspect | StrOutputParser | JsonOutputParser |\n",
                "|--------|-----------------|------------------|\n",
                "| **Output Type** | String | Dictionary |\n",
                "| **Structure** | Unstructured | Structured (JSON) |\n",
                "| **Validation** | None | JSON validation |\n",
                "| **Type Access** | Manual parsing | Direct `dict` access |\n",
                "| **Flexibility** | High | Medium |\n",
                "\n",
                "### Injecting Format Instructions\n",
                "\n",
                "- `parser.get_format_instructions()`: Returns JSON formatting instructions\n",
                "- `partial_variables`: Pre-fills template variables (no manual injection needed)\n",
                "- Model automatically sees formatting rules in prompt\n",
                "\n",
                "### When to Use\n",
                "\n",
                "✅ **Use JsonOutputParser when:**\n",
                "- Output needs flexible structure\n",
                "- Don't have a strict schema\n",
                "- JSON is acceptable format\n",
                "- Need dictionary access\n",
                "\n",
                "❌ **Don't use when:**\n",
                "- Need strict type validation\n",
                "- JSON structure must follow a schema\n",
                "- Type safety is critical\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "1349ddee",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'name': 'Sarah Mitchell', 'age': 32, 'address': '742 Evergreen Terrace, Springfield, IL 62701'}\n"
                    ]
                }
            ],
            "source": [
                "# JsonOutputParser\n",
                "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
                "from langchain_core.prompts import PromptTemplate\n",
                "from langchain_core.output_parsers import JsonOutputParser\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "load_dotenv()\n",
                "\n",
                "#model \n",
                "llm = HuggingFaceEndpoint(\n",
                "    repo_id=\"MiniMaxAI/MiniMax-M2.1\",\n",
                "    task=\"text-generation\")\n",
                "model = ChatHuggingFace(llm = llm)\n",
                "\n",
                "#OutputParser\n",
                "parser = JsonOutputParser()\n",
                "\n",
                "#template\n",
                "template = PromptTemplate(\n",
                "    template=\"give me a name, age, address of a fictional character.\\n {format_instruction}\",\n",
                "    input_variables=[],\n",
                "    partial_variables={\"format_instruction\": parser.get_format_instructions()}\n",
                ")\n",
                "\n",
                "chain = template | model | parser\n",
                "result = chain.invoke({})\n",
                "print(result)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "expl-2",
            "metadata": {},
            "source": [
                "## PydanticOutputParser\n",
                "\n",
                "### Definition\n",
                "\n",
                "**PydanticOutputParser** is the most powerful output parser. It uses **Pydantic models** to define strict schemas with type validation, constraints, and error handling.\n",
                "\n",
                "### Key Features\n",
                "\n",
                "- **Type Safety**: Enforce specific types (str, int, list, etc.)\n",
                "- **Validation**: Complex validation rules (gt, lt, regex patterns)\n",
                "- **Schema Definition**: Exact field structure enforced\n",
                "- **Error Messages**: Clear feedback if validation fails\n",
                "- **Type Hints**: Full IDE support and autocomplete\n",
                "- **Composable**: Works seamlessly with chains\n",
                "\n",
                "### How It Works\n",
                "\n",
                "```\n",
                "1. Define Pydantic Schema (Blueprint)\n",
                "   class Person(BaseModel):\n",
                "       name: str\n",
                "       age: int\n",
                "       email: str\n",
                "\n",
                "2. LLM generates output (JSON string)\n",
                "   {\"name\": \"Alice\", \"age\": 30, \"email\": \"alice@example.com\"}\n",
                "\n",
                "3. Parser validates against schema\n",
                "   ✓ Passes validation\n",
                "\n",
                "4. Returns typed object\n",
                "   person.name → \"Alice\"\n",
                "   person.age → 30\n",
                "```\n",
                "\n",
                "### Use Cases\n",
                "\n",
                "- Strict data validation\n",
                "- API request/response validation\n",
                "- Database model generation\n",
                "- Form data extraction\n",
                "- Production applications requiring reliability\n",
                "\n",
                "### Validation Rules\n",
                "\n",
                "```python\n",
                "from pydantic import BaseModel, Field\n",
                "\n",
                "class Person(BaseModel):\n",
                "    name: str = Field(description=\"Full name\")\n",
                "    age: int = Field(gt=0, lt=150, description=\"Age in years\")\n",
                "    email: str = Field(regex=r\"[\\w\\.-]+@[\\w\\.-]+\\.\\w+\")\n",
                "    role: str = Field(default=\"user\", description=\"User role\")\n",
                "```\n",
                "\n",
                "### Comparison: All Three Parsers\n",
                "\n",
                "| Feature | StrOutputParser | JsonOutputParser | PydanticOutputParser |\n",
                "|---------|-----------------|------------------|----------------------|\n",
                "| **Output Type** | String | Dictionary | Typed Object |\n",
                "| **Schema** | None | Optional | Required |\n",
                "| **Validation** | None | JSON only | Full type checking |\n",
                "| **Constraints** | None | None | Yes (gt, lt, regex) |\n",
                "| **Type Safety** | None | Basic | Full |\n",
                "| **Complexity** | Low | Medium | High |\n",
                "| **Speed** | Fastest | Fast | Slightly slower |\n",
                "| **Best For** | Simple text | Flexible JSON | Strict requirements |\n",
                "\n",
                "### When to Use\n",
                "\n",
                "✅ **Use PydanticOutputParser when:**\n",
                "- Type safety is critical\n",
                "- Validation rules required\n",
                "- Production applications\n",
                "- Need IDE autocomplete\n",
                "- Complex data structures\n",
                "\n",
                "❌ **Don't use when:**\n",
                "- Simple text output needed\n",
                "- Structure varies frequently\n",
                "- Minimal validation required\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "675886a1",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "name='Rajiv Menon' age=28 address='24, Gandhi Nagar, Chennai, Tamil Nadu, India'\n"
                    ]
                }
            ],
            "source": [
                "# PydenticOutputParser\n",
                "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
                "from langchain_core.prompts import PromptTemplate\n",
                "from langchain_core.output_parsers import PydanticOutputParser\n",
                "from pydantic import BaseModel, Field\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "load_dotenv()\n",
                "\n",
                "#model \n",
                "llm = HuggingFaceEndpoint(\n",
                "    repo_id=\"MiniMaxAI/MiniMax-M2.1\",\n",
                "    task=\"text-generation\")\n",
                "model = ChatHuggingFace(llm = llm)\n",
                "\n",
                "class Person(BaseModel):\n",
                "    name: str = Field(description='Persons name')\n",
                "    age : int = Field(gt=18, description=\"Age of Person\")\n",
                "    address : str = Field(description=\"Place where person belongs to\")\n",
                "\n",
                "\n",
                "parser = PydanticOutputParser(pydantic_object=Person)\n",
                "\n",
                "template = PromptTemplate(\n",
                "    template= \"get me name, age, address of a fictional {type} Person.\\n {format_instruction}\",\n",
                "    input_variables=[\"type\"],\n",
                "    partial_variables={\"format_instruction\": parser.get_format_instructions()}\n",
                ")\n",
                "\n",
                "chain = template | model | parser\n",
                "result = chain.invoke({\"type\": \"indian\"})\n",
                "print(result)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4fce2de4",
            "metadata": {},
            "source": [
                "## Best Practices for Output Parsers\n",
                "\n",
                "### 1. Choose the Right Parser\n",
                "\n",
                "**Decision Tree:**\n",
                "\n",
                "```\n",
                "Does output need structure?\n",
                "├─ NO → Use StrOutputParser\n",
                "├─ YES → Need strict schema?\n",
                "    ├─ NO → Use JsonOutputParser\n",
                "    └─ YES → Use PydanticOutputParser\n",
                "```\n",
                "\n",
                "### 2. Design Your Schema First\n",
                "\n",
                "```python\n",
                "from pydantic import BaseModel, Field\n",
                "from typing import List, Optional\n",
                "\n",
                "# ✅ GOOD: Clear, well-documented schema\n",
                "class ProductReview(BaseModel):\n",
                "    \"\"\"A product review with validation\"\"\"\n",
                "    product_name: str = Field(min_length=1, description=\"Name of product\")\n",
                "    rating: int = Field(ge=1, le=5, description=\"Rating from 1-5\")\n",
                "    pros: List[str] = Field(min_items=1, description=\"Positive aspects\")\n",
                "    cons: List[str] = Field(description=\"Negative aspects\")\n",
                "    recommendation: bool = Field(description=\"Would recommend?\")\n",
                "    reviewer_name: Optional[str] = Field(default=None, description=\"Reviewer name\")\n",
                "\n",
                "# ❌ BAD: No validation, unclear structure\n",
                "class Review(BaseModel):\n",
                "    text: str\n",
                "    data: dict\n",
                "```\n",
                "\n",
                "### 3. Add Clear Format Instructions\n",
                "\n",
                "```python\n",
                "from langchain_core.prompts import PromptTemplate\n",
                "from langchain_core.output_parsers import PydanticOutputParser\n",
                "from pydantic import BaseModel, Field\n",
                "\n",
                "class Review(BaseModel):\n",
                "    rating: int = Field(description=\"1-5 star rating\")\n",
                "    summary: str = Field(description=\"One sentence summary\")\n",
                "\n",
                "parser = PydanticOutputParser(pydantic_object=Review)\n",
                "\n",
                "# ✅ GOOD: Explicit format instruction in prompt\n",
                "prompt = PromptTemplate(\n",
                "    template=\"\"\"Analyze this product review and provide structured output:\n",
                "    \n",
                "Review: {review_text}\n",
                "\n",
                "{format_instruction}\"\"\",\n",
                "    input_variables=[\"review_text\"],\n",
                "    partial_variables={\"format_instruction\": parser.get_format_instructions()}\n",
                ")\n",
                "\n",
                "# ❌ BAD: No format instructions\n",
                "prompt = PromptTemplate(\n",
                "    template=\"Analyze this review: {review_text}\",\n",
                "    input_variables=[\"review_text\"]\n",
                ")\n",
                "```\n",
                "\n",
                "### 4. Error Handling and Retry\n",
                "\n",
                "```python\n",
                "from langchain_core.output_parsers import JsonOutputParser\n",
                "from langchain_core.exceptions import OutputParserException\n",
                "\n",
                "parser = JsonOutputParser()\n",
                "\n",
                "try:\n",
                "    result = parser.parse(model_output)\n",
                "except OutputParserException as e:\n",
                "    print(f\"Parse error: {e}\")\n",
                "    # Implement retry logic\n",
                "```\n",
                "\n",
                "### 5. Testing Your Parser\n",
                "\n",
                "```python\n",
                "# ✅ Test with expected output\n",
                "test_output = '{\"name\": \"Alice\", \"age\": 30}'\n",
                "result = parser.parse(test_output)\n",
                "assert result[\"name\"] == \"Alice\"\n",
                "\n",
                "# ✅ Test validation rules\n",
                "invalid_output = '{\"name\": \"Bob\", \"age\": -5}'  # Should fail (age constraint)\n",
                "try:\n",
                "    result = parser.parse(invalid_output)\n",
                "except Exception:\n",
                "    print(\"Validation correctly rejected invalid data\")\n",
                "\n",
                "# ✅ Test edge cases\n",
                "edge_cases = [\n",
                "    '{\"name\": \"\", \"age\": 0}',  # Empty/zero values\n",
                "    '{\"name\": \"X\" * 1000}',     # Very long string\n",
                "    '{}',                        # Missing fields\n",
                "]\n",
                "```\n",
                "\n",
                "### 6. Performance Optimization\n",
                "\n",
                "```python\n",
                "# ✅ GOOD: Cache parser instances\n",
                "parsers = {\n",
                "    \"review\": PydanticOutputParser(pydantic_object=Review),\n",
                "    \"product\": PydanticOutputParser(pydantic_object=Product),\n",
                "}\n",
                "\n",
                "# ✅ GOOD: Reuse format instructions\n",
                "for prompt_id, prompt_template in prompts.items():\n",
                "    instructions = parser.get_format_instructions()\n",
                "    # Use same instructions (cached)\n",
                "\n",
                "# ❌ BAD: Creating new parser for each request\n",
                "for item in items:\n",
                "    parser = PydanticOutputParser(pydantic_object=Review)  # Wasteful\n",
                "```\n",
                "\n",
                "### 7. Common Parsing Errors and Solutions\n",
                "\n",
                "| Error | Cause | Solution |\n",
                "|-------|-------|----------|\n",
                "| **OutputParserException** | Invalid JSON/format | Add format instructions, retry with better prompt |\n",
                "| **ValidationError** | Data doesn't match schema | Relax constraints or improve prompt |\n",
                "| **KeyError** | Missing dictionary key | Add all expected fields to schema |\n",
                "| **TypeError** | Wrong data type | Check type hints in schema |\n",
                "\n",
                "## Summary: Output Parsers\n",
                "\n",
                "### Parser Comparison Quick Reference\n",
                "\n",
                "| Parser | Output | Use When | Effort |\n",
                "|--------|--------|----------|--------|\n",
                "| **StrOutputParser** | String | Simple text output | Low |\n",
                "| **JsonOutputParser** | Dict | Flexible structure | Medium |\n",
                "| **PydanticOutputParser** | Typed Object | Strict validation | High |\n",
                "\n",
                "### Key Takeaways\n",
                "\n",
                "1. **Right Parser**: Choose based on structure needs\n",
                "2. **Format Instructions**: Always inject them via `partial_variables`\n",
                "3. **Validation Rules**: Use Pydantic constraints (gt, lt, regex)\n",
                "4. **Error Handling**: Implement try-except and retry logic\n",
                "5. **Testing**: Test edge cases and invalid inputs\n",
                "6. **Performance**: Cache parsers and instructions\n",
                "7. **Type Safety**: Pydantic for production, Json for prototyping\n",
                "\n",
                "### Common Patterns\n",
                "\n",
                "```python\n",
                "# Pattern 1: Simple text\n",
                "parser = StrOutputParser()\n",
                "chain = prompt | model | parser\n",
                "\n",
                "# Pattern 2: JSON structure\n",
                "parser = JsonOutputParser()\n",
                "chain = prompt | model | parser\n",
                "\n",
                "# Pattern 3: Strict schema\n",
                "class Data(BaseModel):\n",
                "    field: type = Field(...)\n",
                "\n",
                "parser = PydanticOutputParser(pydantic_object=Data)\n",
                "prompt = PromptTemplate(\n",
                "    template=\"...\\n{format_instruction}\",\n",
                "    partial_variables={\"format_instruction\": parser.get_format_instructions()}\n",
                ")\n",
                "chain = prompt | model | parser\n",
                "\n",
                "# Pattern 4: Chaining parsers\n",
                "chain = (\n",
                "    prompt1 | model | str_parser |  # Get structured text\n",
                "    prompt2 | model | json_parser   # Parse to JSON\n",
                ")\n",
                "```\n",
                "\n",
                "### Next Steps\n",
                "\n",
                "After mastering output parsers:\n",
                "1. **Chains**: Combine parsers with prompts and models\n",
                "2. **Validation**: Implement error handling and recovery\n",
                "3. **Custom Parsers**: Create specialized parsers for domain-specific formats\n",
                "4. **Agents**: Use parsers for agent action/input parsing\n",
                "5. **RAG**: Parse retrieved documents\n",
                "\n",
                "### Additional Resources\n",
                "\n",
                "- [Pydantic Documentation](https://docs.pydantic.dev/)\n",
                "- [LangChain Parsers Docs](https://python.langchain.com/docs/modules/model_io/output_parsers/)\n",
                "- [Output Parser API Reference](https://api.python.langchain.com/en/latest/output_parsers/langchain_core.output_parsers.base.OutputParser.html)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
